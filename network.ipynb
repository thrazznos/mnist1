{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing c:\\projects\\tinygrad\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Building wheels for collected packages: tinygrad\n",
      "  Building wheel for tinygrad (pyproject.toml): started\n",
      "  Building wheel for tinygrad (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for tinygrad: filename=tinygrad-0.10.1-py3-none-any.whl size=1438385 sha256=9fa902f476bfd7884cab21276f3a77644b65ec3eb30275a3384258fdae17cbc6\n",
      "  Stored in directory: C:\\Users\\Nathan\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-16g_h9ua\\wheels\\31\\6a\\4d\\db7bda76389de9857b72005b69e072a50366eb4ebc01fa8dc1\n",
      "Successfully built tinygrad\n",
      "Installing collected packages: tinygrad\n",
      "Successfully installed tinygrad-0.10.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install C:/projects/tinygrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU\n"
     ]
    }
   ],
   "source": [
    "import tinygrad\n",
    "\n",
    "from tinygrad import Device\n",
    "\n",
    "print(Device.DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinygrad import Tensor, nn, Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tensor([1, 2, 3]).data().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m*** GPU        5\u001b[0m \u001b[33mcopy        8,     GPU <- PYTHON \u001b[0m         arg  2 mem  0.00 GB tm    717.10us/     0.72ms (     0.00 GFLOPS    0.0|0.0     GB/s) \n",
      "\u001b[32m*** GPU        6\u001b[0m \u001b[33mcopy        8,     GPU <- PYTHON \u001b[0m         arg  2 mem  0.00 GB tm    407.50us/     1.12ms (     0.00 GFLOPS    0.0|0.0     GB/s) \n",
      "E_\u001b[36m2\u001b[0m\u001b[90m\u001b[0m\n",
      " 0: (2,)                      int.ptr(2)           (1,)\n",
      " 1: (2,)                      int.ptr(2)           (1,)\n",
      " 2: (2,)                      int.ptr(2)           (1,)\n",
      "[Opt(op=OptOps.LOCAL, axis=0, arg=2)]\n",
      "__kernel void E_2(__global int* data0, __global int* data1, __global int* data2) {\n",
      "  int lidx0 = get_local_id(0); /* 2 */\n",
      "  int val0 = *(data1+lidx0);\n",
      "  int val1 = *(data2+lidx0);\n",
      "  *(data0+lidx0) = (val0+val1);\n",
      "}\n",
      "\u001b[32m*** GPU        7\u001b[0m E_\u001b[36m2\u001b[0m\u001b[90m\u001b[0m                                       arg  3 mem  0.00 GB tm      1.08us/     1.13ms (     0.00 GFLOPS    0.0|0.0     GB/s) ['__add__', 'tolist']\n",
      "\u001b[32m*** CLANG      8\u001b[0m \u001b[33mcopy        8,   CLANG <- GPU    \u001b[0m         arg  2 mem  0.00 GB tm    274.00us/     1.40ms (     0.00 GFLOPS    0.0|0.0     GB/s) ['tolist']\n",
      "[3, 3]\n"
     ]
    }
   ],
   "source": [
    "with Context(DEBUG=4):\n",
    "    x = Tensor([1, 1])\n",
    "    y = Tensor([2, 2])\n",
    "    z = x + y\n",
    "    print(z.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E_\u001b[34m125\u001b[0m\u001b[90m_\u001b[0m\u001b[36m2\u001b[0m\u001b[90m_\u001b[0m\u001b[33m4\u001b[0m\u001b[90m\u001b[0m\n",
      " 0: (125, 2, 4)               float.ptr(1000)      (8, 4, 1)\n",
      "[Opt(op=OptOps.UPCAST, axis=0, arg=4), Opt(op=OptOps.LOCAL, axis=0, arg=2)]\n",
      "__kernel void E_125_2_4(__global float* data0) {\n",
      "  int gidx0 = get_group_id(0); /* 125 */\n",
      "  int lidx0 = get_local_id(0); /* 2 */\n",
      "  *((__global float4*)((data0+((gidx0<<3)+(lidx0<<2))))) = (float4)(2.0f,2.0f,2.0f,2.0f);\n",
      "}\n",
      "\u001b[32m*** GPU        9\u001b[0m E_\u001b[34m125\u001b[0m\u001b[90m_\u001b[0m\u001b[36m2\u001b[0m\u001b[90m_\u001b[0m\u001b[33m4\u001b[0m\u001b[90m\u001b[0m                                 arg  1 mem  0.00 GB tm      3.20us/     1.40ms (     0.00 GFLOPS    1.2|1.2     GB/s) ['tolist']\n",
      "\u001b[32m*** CLANG     10\u001b[0m \u001b[33mcopy     4000,   CLANG <- GPU    \u001b[0m         arg  2 mem  0.00 GB tm    361.90us/     1.76ms (     0.00 GFLOPS    0.0|0.0     GB/s) ['tolist']\n",
      "[2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0]\n"
     ]
    }
   ],
   "source": [
    "with Context(DEBUG=4):\n",
    "    x = Tensor.ones(1000)\n",
    "    y = Tensor.ones(1000)\n",
    "    z = x + y\n",
    "    print(z.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self):\n",
    "        self.l1 = nn.Conv2d(1, 32, kernel_size=(3, 3))\n",
    "        self.l2 = nn.Conv2d(32, 64, kernel_size=(3, 3))\n",
    "        self.l3 = nn.Linear(1600, 10)\n",
    "    \n",
    "    def __call__(self, x:Tensor) -> Tensor:\n",
    "        x = self.l1(x).relu().max_pool2d((2, 2))\n",
    "        x = self.l2(x).relu().max_pool2d((2, 2))\n",
    "        return self.l3(x.flatten(1).dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Model at 0x24e751cba10>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "https://storage.googleapis.com/cvdf-datasets/mnist/train-images-idx3-ubyte.gz: 4\n",
      "https://storage.googleapis.com/cvdf-datasets/mnist/train-labels-idx1-ubyte.gz: 6\n",
      "https://storage.googleapis.com/cvdf-datasets/mnist/t10k-images-idx3-ubyte.gz: 7.\n",
      "https://storage.googleapis.com/cvdf-datasets/mnist/t10k-labels-idx1-ubyte.gz: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(60000, 1, 28, 28)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tinygrad.nn.datasets import mnist\n",
    "x_train, y_train, x_test, y_test = mnist()\n",
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0778999999165535\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "\n",
    "acc = (model(x_test).argmax(axis = 1) == y_test).mean()\n",
    "\n",
    "print(acc.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = nn.optim.Adam(nn.state.get_parameters(model))\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "def step():\n",
    "    Tensor.training = True\n",
    "    samples = Tensor.randint(batch_size, high=x_train.shape[0])\n",
    "\n",
    "    x, y = x_train[samples], y_train[samples]\n",
    "\n",
    "    optim.zero_grad()\n",
    "\n",
    "    loss = model(x).sparse_categorical_crossentropy(y).backward()\n",
    "    optim.step()\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[17.196870899992064,\n",
       " 2.979917899996508,\n",
       " 0.1161939000012353,\n",
       " 0.11727349998545833,\n",
       " 0.11661029999959283]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "timeit.repeat(step, repeat=5, number=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3449999988079071\n"
     ]
    }
   ],
   "source": [
    "acc = (model(x_test).argmax(axis = 1) == y_test).mean()\n",
    "\n",
    "print(acc.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinygrad import TinyJit\n",
    "\n",
    "jit_step = TinyJit(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0021726999839302152,\n",
       " 0.001881500007584691,\n",
       " 0.0021829000033903867,\n",
       " 0.0017128000035881996,\n",
       " 0.00157789999502711,\n",
       " 0.0013420000032056123,\n",
       " 0.001292400003876537,\n",
       " 0.0014533000066876411,\n",
       " 0.0028750000055879354,\n",
       " 0.0014076000079512596,\n",
       " 0.001264000020455569,\n",
       " 0.0012578000023495406,\n",
       " 0.0013394999841693789,\n",
       " 0.001320600014878437,\n",
       " 0.001364399999147281,\n",
       " 0.0016627000004518777,\n",
       " 0.001295199996093288,\n",
       " 0.0012296000204514712,\n",
       " 0.001260000019101426,\n",
       " 0.0012584000069182366,\n",
       " 0.0015312999894376844,\n",
       " 0.0013288999907672405,\n",
       " 0.001277000003028661,\n",
       " 0.0012571999977808446,\n",
       " 0.0014174999960232526,\n",
       " 0.0012271000014152378,\n",
       " 0.0012771000037901103,\n",
       " 0.001264699996681884,\n",
       " 0.0013056000170763582,\n",
       " 0.0012614000006578863,\n",
       " 0.001299499999731779,\n",
       " 0.0013464999792631716,\n",
       " 0.001246399973751977,\n",
       " 0.0011756999883800745,\n",
       " 0.001183400017907843,\n",
       " 0.0017502999980933964,\n",
       " 0.0029174000083003193,\n",
       " 0.0015038999845273793,\n",
       " 0.0011666000063996762,\n",
       " 0.0011547999747563154,\n",
       " 0.0012123000051360577,\n",
       " 0.0014792000001762062,\n",
       " 0.0018072999955620617,\n",
       " 0.0029092000040691346,\n",
       " 0.003054800006793812,\n",
       " 0.0029949000163469464,\n",
       " 0.0015204999945126474,\n",
       " 0.0021590999967884272,\n",
       " 0.0028350000211503357,\n",
       " 0.00535900000249967,\n",
       " 0.002575899998191744,\n",
       " 0.0023739000025670975,\n",
       " 0.002737000002525747,\n",
       " 0.0016929999983403832,\n",
       " 0.0012063000176567584,\n",
       " 0.0011066000151913613,\n",
       " 0.0011009000008925796,\n",
       " 0.0011467000003904104,\n",
       " 0.0014707999944221228,\n",
       " 0.002960799989523366,\n",
       " 0.0027886999887414277,\n",
       " 0.002582000015536323,\n",
       " 0.0016792000096756965,\n",
       " 0.0012903999886475503,\n",
       " 0.0013337999989744276,\n",
       " 0.0016238999960478395,\n",
       " 0.0015144000062718987,\n",
       " 0.001570199994603172,\n",
       " 0.0016851999971549958,\n",
       " 0.0013509999844245613,\n",
       " 0.0014688999799545854,\n",
       " 0.0015539999876637012,\n",
       " 0.0015087000210769475,\n",
       " 0.0012257000198587775,\n",
       " 0.0012377999955788255,\n",
       " 0.0011625999759417027,\n",
       " 0.001377999986289069,\n",
       " 0.0015875999815762043,\n",
       " 0.0012308000004850328,\n",
       " 0.0015964999911375344,\n",
       " 0.0013967000122647732,\n",
       " 0.001505899999756366,\n",
       " 0.0013862000196240842,\n",
       " 0.0014713999989908189,\n",
       " 0.0012341999972704798,\n",
       " 0.0014031999744474888,\n",
       " 0.0015854999946895987,\n",
       " 0.0014405999972950667,\n",
       " 0.0016106000111903995,\n",
       " 0.0014100999978836626,\n",
       " 0.0015978000010363758,\n",
       " 0.001609699975233525,\n",
       " 0.001586200000019744,\n",
       " 0.001218299992615357,\n",
       " 0.0012910999939776957,\n",
       " 0.00159420000272803,\n",
       " 0.0014279999886639416,\n",
       " 0.0014224999758880585,\n",
       " 0.0015570000105071813,\n",
       " 0.001406800001859665]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeit.repeat(jit_step, repeat=100, number=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8924999833106995\n"
     ]
    }
   ],
   "source": [
    "acc = (model(x_test).argmax(axis = 1) == y_test).mean()\n",
    "\n",
    "print(acc.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
